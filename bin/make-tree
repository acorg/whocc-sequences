#! /usr/bin/env python3
# -*- Python -*-

"""
Exports seqdb data into fasta.
"""

import sys, os, re, subprocess, traceback
if sys.version_info.major != 3: raise RuntimeError("Run script with python3")
sys.path[:0] = [os.path.dirname(os.path.dirname(os.path.realpath(sys.argv[0])))]
import logging; module_logger = logging.getLogger(__name__)
from pathlib import Path

from whoccseq import seqdb, fasta as fasta_m, garli

# ----------------------------------------------------------------------

def main(args):
    email = "eu@antigenic-cartography.org"
    tre_bin_dir = Path("~/GH/tre2pdf/dist").expanduser().resolve()
    tre_scripts_dir = Path("~/GH/tre2pdf/scripts").expanduser().resolve()
    output_dir = args.output_dir[0]

    if not args.only_import_garli_results:
        os.makedirs(output_dir, exist_ok=True)
        export(output_dir, args)
        job = garli.submit_to_htcondor(number_of_replicates=args.number_of_replicates, source=source_fasta, output_dir=output_dir, attachmentspertaxon=args.attachmentspertaxon, genthreshfortopoterm=args.genthreshfortopoterm, machines=args.machines and args.machines.split(","), email=email)
        job.wait(check_interval_in_seconds=30, verbose=True)
    best_tree, all_trees = garli.find_best_tree(output_dir=output_dir)
    module_logger.info('All trees:\n  {}'.format("\n  ".join("{} {}".format(*t) for t in all_trees)))
    module_logger.info('The best tree is {}'.format(best_tree))
    tree_json = Path(output_dir, "tree.json.xz")
    tree_pdf = Path(output_dir, "tree.pdf")
    subprocess.check_call([str(Path(tre_bin_dir, "newick2json")), str(best_tree), str(tree_json)])
    module_logger.info('The best tree converted to {}'.format(tree_json))
    subprocess.check_call([str(Path(tre_scripts_dir, "tre-continent")), str(tree_json), str(tree_json)])
    module_logger.info('The best tree updated with continents in {}'.format(tree_json))
    subprocess.check_call([str(Path(tre_scripts_dir, "tre-seqdb")), "--dates", "--clade", "--pos=all", "--branch-annotations", "--branch-ids", str(tree_json), str(tree_json)])
    module_logger.info('The best tree updated with dates, clades, branch annotations in {}'.format(tree_json))
    subprocess.check_call([str(Path(tre_bin_dir, "tre2pdf")), "--ladderize", "--fix-labels", "--continents", "--clades", "--show-branch-ids", str(tree_json), str(tree_pdf)])
    module_logger.info('{} for the best tree generated'.format(tree_pdf))
    if not args.only_import_garli_results:
        subprocess.call("echo '{}' | /usr/bin/mail -s '{}' {}".format(sys.argv, sys.argv[0], email), shell=True)

# ----------------------------------------------------------------------

def export(output_dir, args):
    db = seqdb.SeqDB(os.path.expandvars(os.path.expanduser(args.path_to_db)))
    if args.base_seq:
        base_seqs = [e for e in db.iterate_sequences_with_name(args.base_seq)]
        if len(base_seqs) != 1:
            raise ValueError("{} base sequences selected: {}".format(len(base_seqs), " ".join(repr(s.name_hi()) for s in base_seqs)))
        del base_seqs[1:]
        if not args.virus_type:
            args.virus_type = base_seqs[0].virus_type()
        elif db.normalize_virus_type(args.virus_type) != base_seqs[0].virus_type():
            raise ValueError("Virus type {} requested conflicts with base sequence virus type {}".format(args.virus_type, base_seqs[0].virus_type()))
    else:
        base_seqs = []
    seqs = list(db.iterate_sequences_with(
        virus_types=args.virus_type,
        lineage=args.lineage,
        gene="HA",
        aligned=True,
        start_date=args.start_date,
        end_date=args.end_date,
        ))
    if args.hamming_distance_threshold:
        most_common_length = seqdb.most_common_length(seqs, amino_acid=False)
        seqs = list(filter(lambda s: base_seqs[0].hamming_distance(s, amino_acid=False, truncate=most_common_length) < args.hamming_distance_threshold, seqs))
    data = sorted(base_seqs + seqs, key=lambda e: e.date() or "0000-00-00")
    module_logger.info('{} entries'.format(len(data)))
    source_fasta = os.path.join(output_dir, "source.fasta")
    fasta_m.export(data=data, output=source_fasta, output_format="fasta", truncate_to_most_common=True, name_format="{seq_id}", amino_acids=False, aligned=True, encode_name=True, wrap=False)

# ----------------------------------------------------------------------

try:
    import argparse
    from whoccseq import utility
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument('output_dir', nargs=1, help='Output dir.')
    parser.add_argument('-d', '--debug', action='store_const', dest='loglevel', const=logging.DEBUG, default=logging.INFO, help='Enable debugging output.')
    # parser.add_argument('--lab', action='store', dest='lab', default=None, help='Export just for this lab.')
    parser.add_argument('--base-seq', action='store', dest='base_seq', default=None, help='Base sequence to export together with other sequences.')
    parser.add_argument('--hamming-distance-threshold', action='store', type=int, dest='hamming_distance_threshold', default=150, help='Select only sequences having hamming distance to the base sequence less than threshold. Use 150 for nucs (H3).')
    parser.add_argument('--flu', action='store', dest='virus_type', default=None, help='Export just for this virus type/subtype: B, H1, H3, A(H1N1), A(H3N2).')
    parser.add_argument('--lineage', action='store', dest='lineage', default=None, help='Export just for this lineage: VICTORIA, YAMAGATA, 2009PDM.')
    # parser.add_argument('--gene', action='store', dest='gene', default="HA", help='HA or NA.')
    # parser.add_argument('--sort', action='store', dest='sort_by', default="date", help='Sort list before exporting by "date", "name".')
    # parser.add_argument('-f', '--format', action='store', dest='output_format', default='fasta', help='Output format: fasta, phylip')
    # parser.add_argument('--name-format', action='store', dest='name_format', default='{name} {passage}', help='Name format, possible fields: {name} {date} {lab_id} {passage} {lab} {gene} {seq_id}. seq_id is used for later matching with seqdb data, e.g. when phylogenetic tree is made.')
    # parser.add_argument('--name-encode', action='store_true', dest='name_encode', default=False, help='Encode spaces and parentheses in names')
    # parser.add_argument('--amino-acids', action='store_true', dest='amino_acids', default=False, help='Export amino-acids instead of nucleotites')
    # parser.add_argument('--no-wrap', action='store_false', dest='sequence_wrap', default=True, help='Do not wrap sequence and generate long lines')
    # parser.add_argument('--aligned', action='store_true', dest='aligned', default=False, help='Write aligned sequences.')
    parser.add_argument('--start-date', action='store', dest='start_date', default=None, help='Export sequences for antigens isolated on or after that date (YYYYMMDD).')
    parser.add_argument('--end-date', action='store', dest='end_date', default=None, help='Export sequences for antigens isolated before that date (YYYYMMDD).')
    # parser.add_argument('--with-hi-name', action='store_true', dest='with_hi_name', default=False, help='Export sequences having hi_name only (i.e. matched with HI data).')
    # parser.add_argument('--name-match', action='store', dest='name_match', default=None, help='Export sequences with names matching this regex.')
    # parser.add_argument('--most-common-length', action='store_true', dest='most_common_length', default=False, help='Truncate or extend with - all sequences to make them all of the same length, most common among original sequences.')
    parser.add_argument('--db', action='store', dest='path_to_db', default='~/WHO/seqdb.json.xz', help='Path to sequence database.')
    parser.add_argument('--replicates', action='store', dest='number_of_replicates', type=int, default=16, help='Number of replicates.')
    parser.add_argument('--attachmentspertaxon', action='store', dest='attachmentspertaxon', type=int, default=2000)
    parser.add_argument('--genthreshfortopoterm', action='store', dest='genthreshfortopoterm', type=int, default=20000)
    parser.add_argument('--machines', action='store', dest='machines', default=None, help="Comma separated list: i19,i20,i21,o16,o17,odette")
    parser.add_argument('--import-garli-results', action='store_true', dest='only_import_garli_results', default=False, help="Do not submit htcondor jobs, just import results")
    args = parser.parse_args()
    logging.basicConfig(level=args.loglevel, format="%(levelname)s %(asctime)s: %(message)s")
    with utility.timeit(sys.argv[0]):
        exit_code = main(args)
except Exception as err:
    logging.error('{}\n{}'.format(err, traceback.format_exc()))
    exit_code = 1
exit(exit_code)

# ======================================================================
### Local Variables:
### eval: (if (fboundp 'eu-rename-buffer) (eu-rename-buffer))
### End:
